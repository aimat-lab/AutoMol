{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mlflow@AIMat\n",
    "\n",
    "[Mlflow](https://mlflow.org) is a platform to manage ML models, track metrics and parameters and create workflows. The AIMat lab runs its own mlflow server which is available on the KIT LAN (or over VPN) under the ip [141.3.29.7](http://141.3.29.7/). If you visit this with your browser you can have a look at the UI.\n",
    "\n",
    "The server is connected to a so-called artifact storage, a mass storage with a fast connection for uploads and downloads, as e.g. trained ML-models, entire code projects, or seperate data - like e.g. numpy arrays, etc. For us this is the Large Scale Data Facility (LSDF) at SCC. It is connected via sftp. The main purpose of this artifact storage is to make it possible for clients to fastly store large amounts of data without the need to send this via a slow web API of the mlflow server itself (see image below). That also means that the client needs direct acces to the artifact store *via the same url as the mlflow server*. More on that in the configuration section. \n",
    "\n",
    "Additionally the server has a so called backend store, which is a managed MySQL database at the SCC. This is needed to store metrics and parameters of models, register models to make pretrained models available to other users, etc. As you can see from the diagram this is only connected directly to the server and needs no configuration from the client side.\n",
    "![Framework-automol-mlflow.jpg](attachment:Framework-automol-mlflow.jpg)\n",
    "\n",
    "## Configuring your clients\n",
    "Your client can be your laptop but also your useraccount on the bwunicluster.\n",
    "We nee three things:\n",
    "- A connection to the LSDF (ask Matthias for an entitlement)\n",
    "- An environment file for mlflow that defines the server address and your credentials\n",
    "- A module that loads the environment file for you\n",
    "\n",
    "### 1. Configuring the LSDF connection\n",
    "The main problem to solve is that the url on your client needs to be the same as on the server. The server url is the following: `sftp://lsdf/kit/iti/projects/aimat-mlflow/artifacts`  \n",
    "To ensure the same url on the client we need to configure the ssh connection. If you not already have an ssh-key pair for the lsdf, create a new one with `ssh-keygen`. As path I recommend `~/.ssh/lsdf`. Add it to your LSDF account with:\n",
    "```bash\n",
    "ssh-copy-id -i ~/.ssh/lsdf user@os-login.lsdf.kit.edu\n",
    "```\n",
    "Now open or create you ssh config with `nano ~/.ssh/config` and add the following lines and replace username with your user:\n",
    "```\n",
    "Host lsdf\n",
    "    HostName os-login.lsdf.kit.edu\n",
    "    User username\n",
    "    IdentityFile ~/.ssh/lsdf\n",
    "```\n",
    "ssh into LSDF with `ssh lsdf` and make sure that you can accesss the storage project for mlflow e.g. with:\n",
    "```bash\n",
    "ls /lsdf/kit/iti/projects/aimat-mlflow\n",
    "```\n",
    "You should see the folder artifacts. If this is not the case, contact your ITB (Matthias)\n",
    "\n",
    "### 2. Create an environment file \n",
    "In your home directory (local laptop) create the file `.env`with `nano .env` and add the follwoing lines:\n",
    "```\n",
    "MLFLOW_TRACKING_USERNAME=user\n",
    "MLFLOW_TRACKING_PASSWORD=your_password\n",
    "MLFLOW_TRACKING_URI=http://141.3.29.7\n",
    "```\n",
    "The password here is a custom generated one which you get from your ITB (Matthias).\n",
    "Now make sure that this file is only readable by you with `chmod 600 .env`\n",
    "\n",
    "### 3. Read and export the variables for mlflow\n",
    "Now that you have your mlflow client configuration in a file that is readable by you, each python code that you execute can read it to use it to authenticate at the server. So you don't have to put your credentials into any code! yay...\n",
    "To read and export the file you can either install mlflow_utils from the aimat package index with:\n",
    "```\n",
    "pip install mlflow_utils --extra-index-url https://aimat-lab.github.io/package-index/\n",
    "```\n",
    "(You need acces to the aimat-lab organization on github)\n",
    "or you can use the follwoing lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "import os\n",
    "\n",
    "\n",
    "def load_env():\n",
    "    home = expanduser(\"~\")\n",
    "    print(home)\n",
    "    with open(home+'/.env', 'r') as f:\n",
    "        env = dict()\n",
    "        for line in f.readlines():\n",
    "            key, value = line.split('=')\n",
    "            env[key] = value.split('\\n')[0]\n",
    "        return env\n",
    "\n",
    "def export_env():\n",
    "    \"\"\"Loads your .env file and exports the three variables important for mlflow.\n",
    "    MLFLOW_TRACKING_USERNAME, MLFLOW_TRACKING_PASSWORD, MLFLOW_TRACKING_URI\n",
    "    \"\"\"\n",
    "    env = load_env()\n",
    "    for key in [\"MLFLOW_TRACKING_USERNAME\", \"MLFLOW_TRACKING_PASSWORD\", \"MLFLOW_TRACKING_URI\"]:\n",
    "        os.environ[key] = env[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`export_env()` can then be called at the beginning of a script or this notebook to automatically export the necessary environment variables.\n",
    "Using this environment file gives you at least a basic security so that you don't have to put credentials into code and e.g. still have them in your git history when publishing a repo. Still on a security breach on the bwunicluster we can renew your password seperately from your actual KIT account password."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using mlflow in your projects\n",
    "\n",
    "**Make sure that you are in the VPN or in the KIT Wifi!!**\n",
    "\n",
    "We first need to install mlflow and for this dummy test-case tensorflow and pandas into our current environment with `pip install mlflow tensorflow pandas`. Now let us first set up mlflow and set the expriment to \"demo\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow_utils.load_env import export_env\n",
    "\n",
    "export_env()\n",
    "mlflow.set_experiment(\"demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for sake of simplicity to demonstrate how mlflow works in conjunction with tensorflow we can work with an example using e.g. the car dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/miniconda2/envs/automol/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  Europe  Japan  USA  \n",
       "393          82       0      0    1  \n",
       "394          82       1      0    0  \n",
       "395          82       0      0    1  \n",
       "396          82       0      0    1  \n",
       "397          82       0      0    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['MPG', Data for 133885 GDB-9 molecules\n",
    "'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "dataset = pd.read_csv(url, names=column_names,\n",
    "                      na_values='?', comment='\\t',\n",
    "                      sep=' ', skipinitialspace=True)\n",
    "dataset = dataset.dropna()\n",
    "# One-hot encode origin:\n",
    "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split it into train and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/miniconda2/envs/automol/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MPG</th>\n",
       "      <td>23.310510</td>\n",
       "      <td>7.728652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cylinders</th>\n",
       "      <td>5.477707</td>\n",
       "      <td>1.699788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Displacement</th>\n",
       "      <td>195.318471</td>\n",
       "      <td>104.331589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horsepower</th>\n",
       "      <td>104.869427</td>\n",
       "      <td>38.096214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>2990.251592</td>\n",
       "      <td>843.898596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acceleration</th>\n",
       "      <td>15.559236</td>\n",
       "      <td>2.789230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Year</th>\n",
       "      <td>75.898089</td>\n",
       "      <td>3.675642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europe</th>\n",
       "      <td>0.178344</td>\n",
       "      <td>0.383413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>0.197452</td>\n",
       "      <td>0.398712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>0.624204</td>\n",
       "      <td>0.485101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean         std\n",
       "MPG             23.310510    7.728652\n",
       "Cylinders        5.477707    1.699788\n",
       "Displacement   195.318471  104.331589\n",
       "Horsepower     104.869427   38.096214\n",
       "Weight        2990.251592  843.898596\n",
       "Acceleration    15.559236    2.789230\n",
       "Model Year      75.898089    3.675642\n",
       "Europe           0.178344    0.383413\n",
       "Japan            0.197452    0.398712\n",
       "USA              0.624204    0.485101"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('MPG')\n",
    "test_labels = test_features.pop('MPG')\n",
    "\n",
    "train_dataset.describe().transpose()[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and fit a normalizer on the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/miniconda2/envs/automol/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(train_features))\n",
    "\n",
    "horsepower = np.array(train_features['Horsepower'])\n",
    "horsepower_normalizer = preprocessing.Normalization(input_shape=[1,])\n",
    "horsepower_normalizer.adapt(horsepower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "        norm,\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlFlowCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\" This Callback logs train and validation metrics to mlflow on every epoch end.\n",
    "    \"\"\"\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        mlflow.log_metrics(metrics=logs, step=epoch)\n",
    "        mlflow.log_metric(key=\"quality\", value=2*epoch, step=epoch)\n",
    "\n",
    "callbacks = [MlFlowCallback()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 22.2859WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0033s vs `on_train_batch_end` time: 0.0350s). Check your callbacks.\n",
      "10/10 [==============================] - 1s 65ms/step - loss: 22.6258 - val_loss: 22.7580\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 74ms/step - loss: 21.6502 - val_loss: 21.6599\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 20.4286 - val_loss: 20.2192\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 18.7620 - val_loss: 18.1932\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 16.4117 - val_loss: 15.4091\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 13.3561 - val_loss: 12.2330\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 60ms/step - loss: 10.1814 - val_loss: 8.8585\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 57ms/step - loss: 7.1841 - val_loss: 5.6427\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 65ms/step - loss: 5.6648 - val_loss: 4.8275\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 4.6762 - val_loss: 3.7616\n"
     ]
    }
   ],
   "source": [
    "mlflow.tensorflow.autolog()\n",
    "model = build_and_compile_model(normalizer)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model.fit(train_features, train_labels,\n",
    "              epochs=10,\n",
    "              validation_data=(test_features, test_labels),\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can head to [http://141.3.29.7](http://141.3.29.7), log in with our user data and "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automol",
   "language": "python",
   "name": "automol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
